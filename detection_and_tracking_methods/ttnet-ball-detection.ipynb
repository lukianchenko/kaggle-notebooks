{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-29T03:16:10.832059Z","iopub.execute_input":"2022-08-29T03:16:10.832671Z","iopub.status.idle":"2022-08-29T03:16:10.861171Z","shell.execute_reply.started":"2022-08-29T03:16:10.832593Z","shell.execute_reply":"2022-08-29T03:16:10.860183Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as T\n\nfrom pathlib import Path\n\nimport cv2\n\nfrom math import exp, pi\nimport math\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\n\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:12.679747Z","iopub.execute_input":"2022-08-29T03:16:12.680481Z","iopub.status.idle":"2022-08-29T03:16:15.458039Z","shell.execute_reply.started":"2022-08-29T03:16:12.680421Z","shell.execute_reply":"2022-08-29T03:16:15.456650Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"batch_size = 1","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.462939Z","iopub.execute_input":"2022-08-29T03:16:15.463533Z","iopub.status.idle":"2022-08-29T03:16:15.469702Z","shell.execute_reply.started":"2022-08-29T03:16:15.463492Z","shell.execute_reply":"2022-08-29T03:16:15.468581Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.472875Z","iopub.execute_input":"2022-08-29T03:16:15.473455Z","iopub.status.idle":"2022-08-29T03:16:15.556156Z","shell.execute_reply.started":"2022-08-29T03:16:15.473417Z","shell.execute_reply":"2022-08-29T03:16:15.554940Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_images_path = Path('/kaggle/input/table-tennis-ball-position-detection-dataset/openttgames/openttgames/images/train')\ntrain_labels_path = Path('/kaggle/input/table-tennis-ball-position-detection-dataset/openttgames/openttgames/labels/train')\n\ntest_images_path = Path('/kaggle/input/table-tennis-ball-position-detection-dataset/openttgames/openttgames/images/test')\ntest_labels_path = Path('/kaggle/input/table-tennis-ball-position-detection-dataset/openttgames/openttgames/labels/test')\n\ntrain_annot_file = Path('/kaggle/input/openttannot/train_dataset_info.csv')\ntest_annot_file = Path('/kaggle/input/openttannot/test_dataset_info.csv')\n\ntrain_df = pd.read_csv(train_annot_file)\ntest_df = pd.read_csv(test_annot_file)\n\ntrain_df = train_df.dropna()\ntest_df = test_df.dropna()\ntrain_df = train_df[train_df['game_id'] == 0]\ntest_df = test_df[test_df['game_id'] == 0]\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.559966Z","iopub.execute_input":"2022-08-29T03:16:15.563178Z","iopub.status.idle":"2022-08-29T03:16:15.704989Z","shell.execute_reply.started":"2022-08-29T03:16:15.563147Z","shell.execute_reply":"2022-08-29T03:16:15.704065Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BallDetectionStage(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n        self.conv_1x1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=1, stride=1, padding=0)\n        self.batch_norm = nn.BatchNorm2d(64)\n        self.relu_1 = nn.ReLU()\n        \n        self.conv_block_1 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        )\n        \n        self.conv_block_2 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        )\n        \n        self.dropout_2d_1 = nn.Dropout2d(p=0.5)\n        \n        self.conv_block_3 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        )\n        \n        self.conv_block_4 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        )\n        \n        self.dropout_2d_2 = nn.Dropout2d(p=0.5)\n        \n        self.conv_block_5 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        )\n        \n        self.conv_block_6 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        )\n        \n        self.dropout_2d_3 = nn.Dropout2d(p=0.5)\n        \n        self.flatten = nn.Flatten()\n        \n        self.general_fc_block = nn.Sequential(\n            nn.Linear(in_features=2560, out_features=1792),\n            nn.ReLU(),\n            nn.Dropout2d(p=0.5)\n        )\n        \n        self.x_fc_block = nn.Sequential(\n            nn.Linear(in_features=1792, out_features=640),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features=640, out_features=320),\n            nn.Sigmoid()\n        )\n        \n        self.y_fc_block = nn.Sequential(\n            nn.Linear(in_features=1792, out_features=256),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features=256, out_features=128),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        x = self.conv_1x1(x)\n        x = self.batch_norm(x)\n        x = self.relu_1(x)\n\n        x = self.conv_block_1(x)\n        x = self.conv_block_2(x)\n        x = self.dropout_2d_1(x)\n\n        x = self.conv_block_3(x)\n        x = self.conv_block_4(x)\n        x = self.dropout_2d_2(x)\n\n        x = self.conv_block_5(x)\n        x = self.conv_block_6(x)\n        x = self.dropout_2d_3(x)\n\n        x = self.flatten(x)\n\n        general_out = self.general_fc_block(x)\n\n        x_out = self.x_fc_block(general_out)\n        y_out = self.y_fc_block(general_out)\n\n        return x_out, y_out","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.706726Z","iopub.execute_input":"2022-08-29T03:16:15.707186Z","iopub.status.idle":"2022-08-29T03:16:15.729161Z","shell.execute_reply.started":"2022-08-29T03:16:15.707146Z","shell.execute_reply":"2022-08-29T03:16:15.728089Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class DetectionModel(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.global_stage = BallDetectionStage()\n        self.local_stage = BallDetectionStage()\n        \n    def __crop_image(self, image, x_c, y_c, height=128, width=320):\n        if x_c in range(width // 2):\n            x_low = 0\n            x_high = width\n        elif x_c in range(image.shape[3] - width // 2, image.shape[3]):\n            x_low = image.shape[3] - width\n            x_high = image.shape[3]\n        else:\n            x_low = x_c - (width // 2)\n            x_high = x_c + (width // 2)\n\n        if y_c in range(height // 2):\n            y_low = 0\n            y_high = height\n        elif y_c in range(image.shape[2] - height // 2, image.shape[2]):\n            y_high = image.shape[2] - height\n            y_low = image.shape[2]\n        else:\n            y_low = y_c - (height // 2)\n            y_high = y_c + (height // 2)\n\n        return image[:, :, y_low:y_high, x_low:x_high]\n        \n    def forward(self, in_image, in_resized):\n        out_global_x, out_global_y = self.global_stage(in_resized)\n        \n        g_x = np.argmax(out_global_x.cpu().detach().numpy())\n        g_y = np.argmax(out_global_y.cpu().detach().numpy())\n        \n        g_x = int((g_x / 320) * 1920)\n        g_y = int((g_y / 128) * 1080)\n        \n        cropped_image = self.__crop_image(in_image, g_x, g_y)\n        \n        out_local_x, out_local_y = self.local_stage(cropped_image)\n        \n        return (out_global_x, out_global_y), (out_local_x, out_local_y)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.731570Z","iopub.execute_input":"2022-08-29T03:16:15.732480Z","iopub.status.idle":"2022-08-29T03:16:15.748152Z","shell.execute_reply.started":"2022-08-29T03:16:15.732435Z","shell.execute_reply":"2022-08-29T03:16:15.747060Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class OpenTTDataset(Dataset):\n    \n    def __init__(self, df, image_dir, transforms=None):\n        super().__init__()\n        self.df = df\n        self.images_ids = df['file_name'].unique()\n        self.image_dir = image_dir\n#         self.image_size = image_size\n        self.transforms = transforms\n        \n    def __transform_coords_to_corners(self, coords, width=320, height=128):\n        x_1 = int(width * coords[0, 0] - width * coords[0, 2] / 2)\n        y_1 = int(height * coords[0, 1] - height * coords[0, 3] / 2)\n        x_2 = int(width * coords[0, 0] + width * coords[0, 2] / 2)\n        y_2 = int(height * coords[0, 1] + height * coords[0, 3] / 2)\n        return x_1, y_1, x_2, y_2\n        \n    def __get_coords(self, coords, stage):\n        if stage == 'global':\n            x_1, y_1, x_2, y_2 = self.__transform_coords_to_corners(coords, width=320, height=128)\n            return x_1 + (x_2 - x_1) // 2, y_1 + (y_2 - y_1) // 2\n        elif stage == 'local':\n            x_1, y_1, x_2, y_2 = self.__transform_coords_to_corners(coords, width=1920, height=1080)\n            x_c = x_1 + (x_2 - x_1) // 2\n            y_c = y_1 + (y_2 - y_1) // 2\n            \n            # MANY MAGIC NUMBERS!!!            \n            if x_c in range(160):\n                x_local = x_c\n            elif x_c in range(1920 - 160, 1920):\n                x_local = 320 - (1920 - x_c)\n            else:\n                x_local = 160\n                \n            if y_c in range(64):\n                y_local = y_c\n            elif y_c in range(1080 - 64, 1080):\n                y_local = 128 - (1080 - y_c)\n            else:\n                y_local = 64\n            return x_local, y_local\n            \n    def __norm_distrib(self, x, m=400, sd=20):\n        return exp(-((x - m) ** 2) / (2 * sd ** 2)) / (sd * ((2 * pi) ** 0.5))        \n                \n    def __getitem__(self, indx):\n        fname = self.images_ids[indx]\n        \n        image = cv2.imread(str(self.image_dir / fname), cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        \n        resized_image = cv2.resize(image, (320, 128))\n        \n        image = torch.tensor(image)\n        image = torch.permute(image, (2,0,1))\n        \n        resized_image = torch.tensor(resized_image)\n        resized_image = torch.permute(resized_image, (2,0,1))\n        \n        coords = self.df[self.df['file_name'] == fname][['a', 'b', 'c', 'd']].values\n        \n        coords_global = self.__get_coords(coords, stage='global')\n        coords_local = self.__get_coords(coords, stage='local')\n        \n        out_coords_x_global = list()\n        out_coords_y_global = list()\n        \n        out_coords_x_local = list()\n        out_coords_y_local = list()\n        \n        for i in range(320):\n            out_coords_x_global.append(self.__norm_distrib(i, m=coords_global[0], sd=5))\n            out_coords_x_local.append(self.__norm_distrib(i, m=coords_local[0], sd=12))\n            \n        \n        for i in range(128):\n            out_coords_y_global.append(self.__norm_distrib(i, m=coords_global[1], sd=5))\n            out_coords_y_local.append(self.__norm_distrib(i, m=coords_local[1], sd=12))\n            \n        out_coords_x_global = torch.tensor(out_coords_x_global).to(torch.float32)\n        out_coords_y_global = torch.tensor(out_coords_y_global).to(torch.float32)\n        \n        out_coords_x_local = torch.tensor(out_coords_x_local).to(torch.float32)\n        out_coords_y_local = torch.tensor(out_coords_y_local).to(torch.float32)\n        \n        return image, resized_image, (out_coords_x_global, out_coords_y_global), (out_coords_x_local, out_coords_y_local)\n    \n    def __len__(self):\n        return self.df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.751679Z","iopub.execute_input":"2022-08-29T03:16:15.752147Z","iopub.status.idle":"2022-08-29T03:16:15.775939Z","shell.execute_reply.started":"2022-08-29T03:16:15.752117Z","shell.execute_reply":"2022-08-29T03:16:15.774890Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Averager:\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val: float, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.779557Z","iopub.execute_input":"2022-08-29T03:16:15.779898Z","iopub.status.idle":"2022-08-29T03:16:15.795984Z","shell.execute_reply.started":"2022-08-29T03:16:15.779873Z","shell.execute_reply":"2022-08-29T03:16:15.794590Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(train_data_loader, model, loss_fn, optimizer, device):\n    \n    model.train()\n    \n    summary_loss = Averager()\n    \n    prog_bar = tqdm(train_data_loader, total=len(train_data_loader))\n    \n    for image, image_resized, global_target, local_target in prog_bar:\n        \n        image = image.to(device)\n        image_resized = image_resized.to(device)\n        \n        global_target = [coords.to(device) for coords in global_target]\n        local_target = [coords.to(device) for coords in local_target]\n        \n        optimizer.zero_grad()\n        \n        global_pred, local_pred = model(image, image_resized)\n        \n        loss_x = loss_fn(global_pred[0], global_target[0]) + loss_fn(local_pred[0], local_target[0])\n        loss_y = loss_fn(global_pred[1], global_target[1]) + loss_fn(local_pred[1], local_target[1])\n        \n        total_loss = loss_x + loss_y\n        \n        total_loss.backward()\n        optimizer.step()\n        \n        summary_loss.update(total_loss, batch_size)\n        prog_bar.set_postfix(loss=summary_loss.avg)\n        \n    return summary_loss","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.802198Z","iopub.execute_input":"2022-08-29T03:16:15.802993Z","iopub.status.idle":"2022-08-29T03:16:15.823059Z","shell.execute_reply.started":"2022-08-29T03:16:15.802950Z","shell.execute_reply":"2022-08-29T03:16:15.818554Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class SaveBestModel:\n\n    def __init__(self, best_loss = 1000):\n        self.best_loss = best_loss\n        \n    def __call__(self, current_loss, epoch, model):\n        if self.best_loss > current_loss:\n            self.best_loss = current_loss\n            print(f'Best model found for epoch {epoch+1}')\n            torch.save(model.state_dict(), 'checkpoint.pth')","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.829827Z","iopub.execute_input":"2022-08-29T03:16:15.834691Z","iopub.status.idle":"2022-08-29T03:16:15.847303Z","shell.execute_reply.started":"2022-08-29T03:16:15.834645Z","shell.execute_reply":"2022-08-29T03:16:15.846208Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train(train_data_loader, test_data_loader, model, loss_fn, optimizer, device, epochs):\n    save_best_model = SaveBestModel()\n    for epoch in range(epochs):\n        print(f'TRAIN EPOCH {epoch+1}')\n        summary_loss = train_one_epoch(train_data_loader, model, loss_fn, optimizer, device)\n        print(f'SUMMARY EPOCH LOSS: {summary_loss.avg}')\n        summary_distance = validate(test_data_loader, model, device)\n        print(f'SUMMARY EPOCH DISTANCE: {summary_distance.avg}')\n        save_best_model(summary_loss.avg, epoch, model)\n        print('---------------------------')","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.852749Z","iopub.execute_input":"2022-08-29T03:16:15.855854Z","iopub.status.idle":"2022-08-29T03:16:15.866393Z","shell.execute_reply.started":"2022-08-29T03:16:15.855816Z","shell.execute_reply":"2022-08-29T03:16:15.864963Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def validate(test_data_loader, model, device):\n    model.eval()\n    \n    averager = Averager()\n    \n    with torch.no_grad():\n        prog_bar = tqdm(test_data_loader, total=len(test_data_loader))\n        \n        for image, resized_image, global_target, local_target in prog_bar:\n            image = image.to(device)\n            resized_image = resized_image.to(device)\n        \n#             global_target = [coords.to(device) for coords in global_target]\n#             local_target = [coords.to(device) for coords in local_target]\n            \n            global_pred, local_pred = model(image, resized_image)\n            \n            g_x_pred = np.argmax(global_pred[0].cpu().numpy())\n            g_y_pred = np.argmax(global_pred[1].cpu().numpy())\n            \n            l_x_pred = np.argmax(local_pred[0].cpu().numpy())\n            l_y_pred = np.argmax(local_pred[1].cpu().numpy())\n            \n            g_x_target = np.argmax(global_target[0].numpy())\n            g_y_target = np.argmax(global_target[1].numpy())\n            \n            l_x_target = np.argmax(local_target[0].numpy())\n            l_y_target = np.argmax(local_target[1].numpy())\n            \n            x_pred = int((g_x_pred * 1920) / 320 - (320 / 2) + l_x_pred)\n            y_pred = int((g_y_pred * 1080) / 128 - (128 / 2) + l_y_pred)\n            \n            x_target = int((g_x_target * 1920) / 320 - (320 / 2) + l_x_target)\n            y_target = int((g_y_target * 1080) / 128 - (128 / 2) + l_y_target)\n            \n            distance = ((x_target - x_pred) ** 2 + (y_target - y_pred) ** 2) ** 0.5\n            \n            averager.update(distance, batch_size)\n            prog_bar.set_postfix(distance = averager.avg)\n            \n    return averager","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.872045Z","iopub.execute_input":"2022-08-29T03:16:15.880734Z","iopub.status.idle":"2022-08-29T03:16:15.891298Z","shell.execute_reply.started":"2022-08-29T03:16:15.880707Z","shell.execute_reply":"2022-08-29T03:16:15.889377Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = OpenTTDataset(train_df, train_images_path)\ntrain_data_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n\ntest_dataset = OpenTTDataset(test_df, test_images_path)\ntest_data_loader = DataLoader(test_dataset, batch_size, shuffle=True)\n\nmodel = DetectionModel()\nmodel = model.to(device)\n\nparams = [p for p in model.parameters() if p.requires_grad]\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params)\n\ntrain(train_data_loader, test_data_loader, model, loss_fn, optimizer, device, 30)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T03:16:15.988917Z","iopub.execute_input":"2022-08-29T03:16:15.989232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}